{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQvTOnj5aIZ8Ct3vbT3tx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saurav-Raghaw/Python/blob/main/PyTorch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQHpZTDmE_qY"
      },
      "source": [
        "############################________Linear Regression With PyTorch FrameWork With Built-in function__________###############################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyBJEluPWo9A"
      },
      "source": [
        "#PyTorch provides several built-in functions and classes to make it easy to create and train models with just a few lines of code.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "#torch.nn package contains utility classes for building neural networks."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8PSgwRgW9LJ"
      },
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "input = torch.from_numpy(inputs)\n",
        "target = torch.from_numpy(targets)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84pzAPf5YdNu"
      },
      "source": [
        "#TensorDataset and DataLoader\n",
        "\n",
        "\n",
        "\n",
        "*   TensorDataset, which allows access to rows from inputs and targets as tuples.\n",
        "*   The TensorDataset allows us to access a small section of the training data using the array indexing notation.\n",
        "*   It returns a tuple with two elements. The first element contains the input variables for the selected rows, and the second contains the targets.\n",
        "*   DataLoader can split the data into batches of a predefined size while training. \n",
        "*   It also provides other utilities like shuffling and random sampling of the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjW3HlRQYb65",
        "outputId": "e95b0c9c-39ac-4d51-ac38-7493c9862a80"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Defining the dataset\n",
        "train_ds = TensorDataset(input, target)\n",
        "train_ds[0:3]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYtv0MTIaLPL"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Defining data loader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJC47Y0TalLB",
        "outputId": "da739cc8-83c2-4ea4-f394-a0f67451d8e9"
      },
      "source": [
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)\n",
        "    break\n",
        "\n",
        "#In each iteration, the data loader returns one batch of data with the given batch size. \n",
        "#If shuffle is set to True, it shuffles the training data before creating batches. \n",
        "#Shuffling helps randomize the input to the optimization algorithm, leading to a faster reduction in the loss."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 87., 134.,  58.],\n",
            "        [ 87., 135.,  57.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 92.,  87.,  64.]])\n",
            "tensor([[119., 133.],\n",
            "        [118., 134.],\n",
            "        [ 80., 102.],\n",
            "        [ 81., 101.],\n",
            "        [ 82., 100.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49yuwkRJeAur"
      },
      "source": [
        "#For Help we can type like.\n",
        "\n",
        "#  ?DataLoader"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPxey9LWeyRa",
        "outputId": "e27dd28f-7b71-4f26-b702-ead25a300e2d"
      },
      "source": [
        "#    nn.Linear\n",
        "\n",
        "#Instead of initializing the weights & biases manually, we can define the model using the nn.Linear class from PyTorch, which does it automatically.\n",
        "# Defining model\n",
        "model = nn.Linear(3, 2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2276,  0.2758, -0.0487],\n",
            "        [ 0.3411, -0.5269,  0.2057]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.5319, 0.5621], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gGRRWChfY8V",
        "outputId": "5e248e1b-8c41-44a9-af12-cd3dbe96c251"
      },
      "source": [
        "# .parameters \n",
        "\n",
        "#PyTorch models also have a helpful .parameters method, which returns a list containing all the weights and bias matrices present in the model. \n",
        "#For our linear regression model, we have one weight matrix and one bias matrix.\n",
        "# Parameters\n",
        "\n",
        "list(model.parameters())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.2276,  0.2758, -0.0487],\n",
              "         [ 0.3411, -0.5269,  0.2057]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.5319, 0.5621], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orz6hMJKf4sc",
        "outputId": "39336d96-2975-478a-f674-3c5f4800ddc0"
      },
      "source": [
        "# Generating the predictions.\n",
        "prediction_ = model(input)\n",
        "prediction_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.9538e-01, -9.9384e-01],\n",
              "        [ 9.6581e-01, -1.5984e+00],\n",
              "        [ 1.4854e+01, -2.8434e+01],\n",
              "        [-1.2633e+01,  2.0308e+01],\n",
              "        [ 7.8879e+00, -1.2082e+01],\n",
              "        [-2.0805e-01, -1.2589e-01],\n",
              "        [ 6.4131e-01, -8.6582e-01],\n",
              "        [ 1.4578e+01, -2.7887e+01],\n",
              "        [-1.2129e+01,  1.9440e+01],\n",
              "        [ 8.0669e+00, -1.2218e+01],\n",
              "        [-2.9118e-02, -2.6121e-01],\n",
              "        [ 4.6238e-01, -7.3050e-01],\n",
              "        [ 1.5179e+01, -2.9166e+01],\n",
              "        [-1.2812e+01,  2.0443e+01],\n",
              "        [ 8.3914e+00, -1.2950e+01]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVjrHxXKglPw"
      },
      "source": [
        "#Loss Function\n",
        "\n",
        "#Instead of defining a loss function manually, we can use the built-in loss function mse_loss.\n",
        "#The nn.functional package contains many useful loss functions and several other utilities.\n",
        "\n",
        "# Importing nn.functional\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Defining the loss function\n",
        "loss_fn = F.mse_loss"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SypwqqFhMYs",
        "outputId": "548a067d-e52f-4cfc-b0a1-f3e8c7537e23"
      },
      "source": [
        "#Computing the loss for the current predictions of our model.\n",
        "\n",
        "loss = loss_fn(prediction_, target)\n",
        "print(loss)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(8944.8076, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYeXmMtchziv"
      },
      "source": [
        "#Optimizer\n",
        "\n",
        "#Instead of manually manipulating the model's weights & biases using gradients, we can use the optimizer optim.SGD. \n",
        "#SGD is short for \"stochastic gradient descent\". The term stochastic indicates that samples are selected in random batches instead of as a single group.\n",
        "\n",
        "# Defining optimizer\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "#Note that model.parameters() is passed as an argument to optim.SGD so that the optimizer knows which matrices should be modified during the update step. \n",
        "#Also, we can specify a learning rate that controls the amount by which the parameters are modified."
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPVgF5VLjGco"
      },
      "source": [
        "#Training the model.\n",
        "\n",
        "*  Generate predictions\n",
        "\n",
        "*  Calculate the loss\n",
        "\n",
        "*  Compute gradients w.r.t the weights and biases\n",
        "\n",
        "*  Adjust the weights by subtracting a small quantity proportional to the gradient\n",
        "\n",
        "*  Reset the gradients to zero\n",
        "\n",
        "We'll work batches of data instead of processing the entire training data in every iteration. We defined a utility function fit that trains the model for a given number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8BJm_OjjeQS"
      },
      "source": [
        "# Utility function to training the model\n",
        "\n",
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    \n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Train with batches of data\n",
        "        for xb,yb in train_dl:\n",
        "            \n",
        "            # 1. Generating predictions\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # 2. Calculating loss\n",
        "            loss = loss_fn(pred, yb)\n",
        "            \n",
        "            # 3. Computing gradients \n",
        "            loss.backward()\n",
        "            \n",
        "            # 4. Update parameters using gradients--Instead of updating parameters (weights and biases) manually, we use opt.step to perform the update.\n",
        "            opt.step()\n",
        "            \n",
        "            # 5. Reset the gradients to zero--opt.zero_grad to reset the gradients to zero.\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Print the progress --prints the loss from the last batch of data for every 10th epoch to track training progress. \n",
        "        #loss.item returns the actual value stored in the loss tensor.\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))  "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRPqJbLalfgd",
        "outputId": "054dd3f9-55a0-4db5-e4b8-fff561c39870"
      },
      "source": [
        "fit(200, model, loss_fn, opt, train_dl)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [10/200], Loss: 19.8506\n",
            "Epoch [20/200], Loss: 22.5004\n",
            "Epoch [30/200], Loss: 13.8141\n",
            "Epoch [40/200], Loss: 12.1865\n",
            "Epoch [50/200], Loss: 12.5050\n",
            "Epoch [60/200], Loss: 4.2958\n",
            "Epoch [70/200], Loss: 5.6107\n",
            "Epoch [80/200], Loss: 3.9160\n",
            "Epoch [90/200], Loss: 6.8802\n",
            "Epoch [100/200], Loss: 9.1331\n",
            "Epoch [110/200], Loss: 7.3606\n",
            "Epoch [120/200], Loss: 4.2813\n",
            "Epoch [130/200], Loss: 5.2800\n",
            "Epoch [140/200], Loss: 4.3814\n",
            "Epoch [150/200], Loss: 5.6619\n",
            "Epoch [160/200], Loss: 7.2535\n",
            "Epoch [170/200], Loss: 4.3161\n",
            "Epoch [180/200], Loss: 4.4131\n",
            "Epoch [190/200], Loss: 2.6443\n",
            "Epoch [200/200], Loss: 3.5485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ0a0QhKl02r",
        "outputId": "669491ba-f75d-4781-96ac-3131f9047d38"
      },
      "source": [
        "#Comaparing with actual target.\n",
        "# Generating predictions\n",
        "\n",
        "prediction_ = model(input)\n",
        "print(prediction_)\n",
        "print(target)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 57.2305,  70.6597],\n",
            "        [ 80.6012,  99.8181],\n",
            "        [121.1195, 134.3393],\n",
            "        [ 21.6665,  38.3948],\n",
            "        [ 98.9722, 116.9606],\n",
            "        [ 55.9515,  69.5663],\n",
            "        [ 80.1944,  99.7727],\n",
            "        [121.2649, 134.8603],\n",
            "        [ 22.9455,  39.4882],\n",
            "        [ 99.8443, 118.0085],\n",
            "        [ 56.8236,  70.6143],\n",
            "        [ 79.3223,  98.7247],\n",
            "        [121.5263, 134.3847],\n",
            "        [ 20.7944,  37.3469],\n",
            "        [100.2512, 118.0539]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8gGfoV_mdrR",
        "outputId": "f175347d-63e0-4fd3-b012-0f8860b9f8dc"
      },
      "source": [
        "#We can use it to make predictions of crop yields for new regions by passing a batch containing a single row of input.\n",
        "\n",
        "model(torch.tensor([[75, 63, 44.]]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[53.3502, 67.5977]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}